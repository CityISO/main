{% extends 'base.html' %}

{% block content %}
     
    <div class="container">
        <div class="content is-medium">
            <h1 class="title">Цель</h1>

            <p>Создать веб-платформу, с помощью которой можно отслеживать настроение жителей города путем семантического
                анализа текста, хэштегов и эмоциональной окраски фотографии в социальных сетях.</p> 


            <h1 class="title is-spaced">Схема работы</h1>
            <ul>
                <li>Парсинг данных из разных источников</li>
                <li>Обработка данных</li>
                <li>Проведение анализа</li>
            </ul>


            <p>Это первый этап. На этом этапе мы собираем данные из социальных сетей для анализа. В ходе разработки наша
                команда выбрала для начала соц. сеть Instagram. Для работы с социальной сетью была выбрана библиотека
                <a href="https://instaloader.github.io/">Instaloader</a>.</p>

            <p>Изначально, чтобы набрать данные, было собрано ~2000 постов. После этого парсинг был поставлен в фоновую
                задачу, чтобы постоянно обновлять данные (не более 100 постов по локации). Выполнение фоновых задач
                осуществляется через Celery. Данные сохраняются в <a href="https://ru.wikipedia.org/wiki/PostgreSQL">PostgreSQL</a>.</p>


            <h1 class="title">Обработка данных</h1>
            <p>После сбора данные необходимо обработать. Для MVP было выбрано несколько направлений - обработка текста,

                тематическое моделирование, а также анализ фотографий. </p>
            <p>Обработка текста проходит в несколько этапов: форматирование текста через регулярное выражение, а после
                все слова в тексте приводятся в начальную форму с помощью <a href="https://pymorphy2.readthedocs.io">pymorphy2</a>. Это
                делается для наивной проверки на рекламные сообщения, т.е через стоп-слова.</p>

            <p>Исходный текст проходит тональный анализ через <a href="https://www.nltk.org/">NLTK</a>. Здесь возникает проблема с
                тем, что NLTK действует лишь для англоязычных текстов, однако это легко исправить, воспользовавшись API
                для работы с <a href="https://cloud.google.com/translate/docs/apis">GoogleTranslator</a>. В связи с необходимостью
                его использования, для устранения ошибок при выполнении программы, используется функция удаления
                смайликов из текста, базирующаяся на библиотеке <a href="https://pypi.org/project/emoji/">emoji</a>. Результат
                анализа записывается в базу данных.</p>

            <p>Для тематического анлаиза текста наша команда использовала библиотеку <a href="https://github.com/igor-shevchenko/rutermextract">rutermextract</a>.</p>

            <p>А для анализа фото была использована библиотека <a href="https://github.com/keras-team">keras</a>. </p>

            <h1 class="title">Отображение данных</h1>
            <p>После обработки данных, их необходимо предоставить пользователю платформы. </p>

            <p>Для этого был выбран WEB фреймворк <a href="https://www.djangoproject.com/">Django</a>. Это обусловлено несколькими причинами: проект легко
                расширяется (поскольку представляется многомодульным, мы решили взять именно Django, а не Flask),
                интеграция с Celery (при добавлении новой локации, нужно просто добавить задачу, аргументом которой
                будет ID локации), легкость добавления представлений для работы API, основной язык разработки проекта - 
                Python. </p>
            <p>Для работы на клиентской стороне выбран JS (VueJS и библиотеки, для работы с картой, графиками).</p>
        </div>
    </div>
{% endblock %}